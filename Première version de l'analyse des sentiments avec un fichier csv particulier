import tensorflow as tf
from transformers import TFBertForSequenceClassification, BertTokenizer, set_seed
import pandas as pd
import numpy as np
import os

# Fixer la seed pour la reproductibilité
set_seed(1, True)

# Charger le modèle et le tokenizer FinBERT
model_path = "ProsusAI/finbert"
tokenizer = BertTokenizer.from_pretrained(model_path)
model = TFBertForSequenceClassification.from_pretrained(model_path)

def aggregate_sentiment_scores(sentiment_scores):
    """ Agrège les scores de sentiment avec un poids exponentiel pour privilégier les textes récents """
    n = sentiment_scores.shape[0]
    weights = np.exp(np.linspace(0, 1, n))
    weights /= weights.sum()
    weighted_scores = sentiment_scores * weights[:, np.newaxis]
    aggregated_scores = weighted_scores.sum(axis=0)
    return aggregated_scores

def analyze_sentiment(texts):
    """ Analyse le sentiment d'une liste de textes """
    if not texts:
        return None
    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors='tf')
    outputs = model(**inputs)
    scores = tf.nn.softmax(outputs.logits, axis=-1).numpy()
    aggregated_scores = aggregate_sentiment_scores(scores)
    return {
        'Negative': float(aggregated_scores[0]),
        'Neutral': float(aggregated_scores[1]),
        'Positive': float(aggregated_scores[2])
    }

def analyze_csv(file_path, text_column='content', symbol_column='stock_symbol'):
    """ Analyse un CSV et renvoie un dictionnaire avec le sentiment pour chaque action """
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"Le fichier {file_path} n'existe pas.")
    
    df = pd.read_csv(file_path)
    
    if text_column not in df.columns or symbol_column not in df.columns:
        raise ValueError(f"Les colonnes '{text_column}' ou '{symbol_column}' n'existent pas dans le CSV")
    
    # On groupe par entreprise pour analyser les commentaires de chaque stock
    sentiment_results = {}
    for stock, group in df.groupby(symbol_column):
        texts = group[text_column].dropna().tolist()
        sentiment_results[stock] = analyze_sentiment(texts)
    
    return sentiment_results

# Exemple d'utilisation
if __name__ == "__main__":
    file_path = "reddit_stock_data_20251016_114603.csv"
    sentiment_by_stock = analyze_csv(file_path, text_column='content', symbol_column='stock_symbol')
    
    # Affichage des résultats
    for stock, sentiment in sentiment_by_stock.items():
        print(f"{stock}: {sentiment}")
